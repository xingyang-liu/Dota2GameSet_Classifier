"""
This program performs two different logistic regression implementations on two
different datasets of the format [float,float,boolean], one
implementation is in this file and one from the sklearn library. The program
then compares the two implementations for how well the can predict the given outcome
for each input tuple in the datasets.

@author Per Harald Borgen
"""

import math
import numpy as np
from numpy import where
from pylab import scatter, show, legend, xlabel, ylabel

##The sigmoid function adjusts the cost function hypotheses to adjust the algorithm proportionally for worse estimations
def Sigmoid(z):
    G_of_Z = float(1.0 / float((1.0 + math.exp(-1.0*z))))
    return G_of_Z

##The hypothesis is the linear combination of all the known factors x[i] and their current estimated coefficients theta[i] 
##This hypothesis will be used to calculate each instance of the Cost Function
def Hypothesis(theta, x):
    z = 0
    for i in xrange(len(theta)):
        z += x[i]*theta[i]
    return Sigmoid(z)

##For each member of the dataset, the result (Y) determines which variation of the cost function is used
##The Y = -1 cost function punishes high probability estimations, and the Y = 1 it punishes low scores
##The "punishment" makes the change in the gradient of ThetaCurrent - Average(CostFunction(Dataset)) greater
def Cost_Function(X,Y,theta,m):
    sumOfErrors = 0
    for i in xrange(m):
        xi = X[i]
        hi = Hypothesis(theta,xi)
        if Y[i] == 1:
            error = Y[i] * math.log(hi)
        elif Y[i] == 0:
            error = (1-Y[i]) * math.log(1-hi)
        sumOfErrors += error
    const = -1/m
    J = const * sumOfErrors
    # print 'cost is ', J
    return J

##This function creates the gradient component for each Theta value 
##The gradient is the partial derivative by Theta of the current value of theta minus 
##a "learning speed factor aplha" times the average of all the cost functions for that theta
##For each Theta there is a cost function calculated for each member of the dataset
def Cost_Function_Derivative(X,Y,theta,j,m,alpha):
    sumErrors = 0
    for i in xrange(m):
        xi = X[i]
        xij = xi[j]
        hi = Hypothesis(theta,X[i])
        error = (hi - Y[i])*xij
        sumErrors += error
    m = len(Y)
    constant = float(alpha)/float(m)
    J = constant * sumErrors
    return J

##For each theta, the partial differential 
##The gradient, or vector from the current point in Theta-space (each theta value is its own dimension) to the more accurate point, 
##is the vector with each dimensional component being the partial differential for each theta value
def Gradient_Descent(X,Y,theta,m,alpha):
    new_theta = []
    constant = alpha/m
    for j in xrange(len(theta)):
        CFDerivative = Cost_Function_Derivative(X,Y,theta,j,m,alpha)
        new_theta_value = theta[j] - CFDerivative
        new_theta.append(new_theta_value)
    return new_theta

##The high level function for the LR algorithm which, for a number of steps (num_iters) finds gradients which take 
##the Theta values (coefficients of known factors) from an estimation closer (new_theta) to their "optimum estimation" which is the
##set of values best representing the system in a linear combination model
def Logistic_Regression(X,Y,alpha,theta,num_iters):
    m = len(Y)
    cost = 0
    prev_cost = 100000
    for x in xrange(num_iters):
        new_theta = Gradient_Descent(X,Y,theta,m,alpha)
        theta = new_theta
        if x % 100 == 0:
            cost = Cost_Function(X,Y,theta,m)
            print cost
            if prev_cost - cost < 0.01:
                break;
            prev_cost = cost
    return theta

##This method compares the accuracy of the model generated by the scikit library with the model generated by this implementation
def LR_Test(X_test, Y_test, theta):
    score = 0
    a = 0
    b = 0
    c = 0
    d = 0
    length = len(X_test)
    for i in xrange(length):
        hi = Hypothesis(X_test[i],theta)
        # hi = X_test[i][0] - X_test[i][1]
        # if hi > thresh:
        #     prediction = 1
        # else:
        #     prediction = 0
        prediction = round(hi)
        print prediction, Y_test[i], hi
        answer = Y_test[i]
        if prediction == 1:
            if answer == 1:
                a += 1
            else:
                c += 1
        else:
            if answer == 1:
                b += 1
            else:
                d += 1
    accuracy = float(a + d) / float(length)
    precision = float(a) / float(a + b)
    recall = float(a) / float(a + c)

    print 'Accuracy: ', accuracy
    print 'Precision: ', precision
    print 'Recall: ', recall

# These are the initial guesses for theta as well as the learning rate of the algorithm
# A learning rate too low will not close in on the most accurate values within a reasonable number of iterations
# An alpha too high might overshoot the accurate values or cause irratic guesses
# Each iteration increases model accuracy but with diminishing returns, 
# and takes a signficicant coefficient times O(n)*|Theta|, n = dataset length
if __name__ == "__main__":
    print('reading training and testing data...')
    train = np.loadtxt('Pre_Process_Train.csv', delimiter=',')
    # train = np.loadtxt('dota2Train.csv', delimiter=',')
    X_train = train[:, 1:]
    Y_train = train[:, 0]
    test = np.loadtxt('Pre_Process_Test.csv', delimiter=',')
    # test = np.loadtxt('dota2Test.csv', delimiter=',')
    X_test = test[:, 1:]
    Y_test = test[:, 0]

    initial_theta = [0 for col in range(2)]
    # initial_theta = [1,-1]
    alpha = 1
    iterations = 1000
    # theta = Logistic_Regression(X_train, Y_train, alpha, initial_theta, iterations)
    LR_Test(X_test, Y_test, initial_theta)

    # visualize data, uncomment "show()" to run it
    pos = where(Y_test == 1)
    neg = where(Y_test == 0)
    scatter(X_test[pos, 0], X_test[pos, 1], marker='o', c='b')
    scatter(X_test[neg, 0], X_test[neg, 1], marker='x', c='r')
    xlabel('Team 1')
    ylabel('Team -1')
    legend(['Team 1 win', 'Team -1 win'])
    show()
